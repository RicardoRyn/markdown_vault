# 空间平滑和标准化（blur & scale）

## blur

做空间平滑的原因

- 在相邻的体素之间做空间平滑，它们的信号中的噪音部分是随机变化的；平滑之后，它们的噪音就会相互抵消，提高信噪比

- 空间平滑之后，激活脑区的范围会变得更大，在进行组分析的时候，不同被试的大脑相同激活脑区的重合度会更高

打开proc.py，部分显示如下：

```bash
# ================================== blur ==================================
# blur each volume of each run
foreach run ( $runs )
    3dmerge -1blur_fwhm 4.0 -doall -prefix pb03.$subj.r$run.blur \  # _fwhm 4.0表示平滑度为4.0，单位为mm（当ROI很小时，平滑度不能设置太高，一般为0~8）；-doall会将整个时间序列上的大脑都进行平滑；-prefix pb03.$subj.r$run.blur为输出的文件（output）
            pb02.$subj.r$run.volreg+tlrc  # 输入的数据（input）
end
```

在终端中打开blur前后的图像进行对比，键入：

```bash
afni pb03.FT.r01.blur+tlrc. pb02.FT.r01.volreg+tlrc.
```



## mask

mask是用来做全脑的mask（但是没有用）

这个mask会把大脑的形状轮廓做出来，然后轮廓之内的值都变成1，轮廓之外的值都为0；但是mask并没有在被试水平应用到大脑里，也就是并没有把大脑之外的数据都去除掉；这个最终会在做组分析的时候用



## scale

在时间序列上的标准化

不同被试信号差异的绝对值不一样，但是信号差异的百分比可能一样，所以需要进行标准化

计算出一个体素的时间序列的平均值，然后除以这个平均值再乘以100，使整个时间序列的值在100上下浮动，代表了信号的百分比

打开proc.py，部分显示如下：

```bash
# ================================= scale ==================================
# scale each voxel time series to have a mean of 100
# (be sure no negatives creep in)
# (subject to a range of [0,200])
foreach run ( $runs )
    3dTstat -prefix rm.mean_r$run pb03.$subj.r$run.blur+tlrc  # 计算平均值
    3dcalc -a pb03.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \  # -a表示做过平滑的原始数据；-b表示刚刚计算出的平均值
           -c mask_epi_extents+tlrc                            \  # 表示整个镜头的mask，空间配准的时候用到过
           -expr 'c * min(200, a/b*100)*step(a)*step(b)'       \  # 计算标准化的公式，200和你计算得到的值谁更小，就选谁，因为大脑信号百分比不可能新增100%，超过200就不符合常理，只会取200；乘以c表示只能是镜头里的值（因为这个mask是个1/0矩阵，只会保留镜头以内的值）；step(a)和step(b)都表示大于0的值变为1，小于0的值变为0
           -prefix pb04.$subj.r$run.scale  # 生成的数据（output）
end
```

在终端中打开scale前后的图像进行对比，键入：

```bash
afni pb03.FT.r01.blur+tlrc. pb04.FT.r01.scale+tlrc.
```

